{"cells":[{"cell_type":"markdown","metadata":{"id":"m_Mt_VHr1yOa"},"source":["### **MOUNTING DRIVE TO ACCESS AND SAVE DATA**"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5RWS8J41yOe","executionInfo":{"status":"ok","timestamp":1692817269432,"user_tz":-330,"elapsed":3399,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}},"outputId":"e999c0dd-8124-435b-9cd0-59f8f3941988"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"ua_T6ksi1yOf"},"source":["### **IMPORTING RELEVANT MODULES**"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U06Q8wxb1yOf","executionInfo":{"status":"ok","timestamp":1692817269432,"user_tz":-330,"elapsed":5,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}},"outputId":"6de889c3-df98-41c4-c51f-0b202ce3f73c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":30}],"source":["import numpy as np\n","import pandas as pd\n","import nltk\n","import pickle\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.models import load_model\n","nltk.download('punkt')\n","nltk.download('stopwords')"]},{"cell_type":"markdown","metadata":{"id":"yZ81q5Xj1yOg"},"source":["### **TOKENIZING AND PREPROCESSING TWEETS**"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"gvTkcXgy1yOg","executionInfo":{"status":"ok","timestamp":1692817270722,"user_tz":-330,"elapsed":1293,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}}},"outputs":[],"source":["stop_words = set(stopwords.words('english'))\n","\n","def preprocess_text(text):\n","    if type(text) != float:\n","        tokens = word_tokenize(text.lower())\n","        filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n","        return ' '.join(filtered_tokens)\n","    else:\n","        return str(text)\n","\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/extern.csv')\n","\n","df['preprocessed_tweet'] = df['tweet'].apply(preprocess_text)\n","X = df['preprocessed_tweet'].values\n","y = df['value'].values"]},{"cell_type":"markdown","metadata":{"id":"-3h3ecIX1yOh"},"source":["### **DIVIDING INTO TRAIN AND VALIDATION SET**"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"2FFqqJ9w1yOh","executionInfo":{"status":"ok","timestamp":1692817272298,"user_tz":-330,"elapsed":551,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}}},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","vocab_size = 50000  # Maximum number of words in the vocabulary\n","embedding_dim = 100\n","max_length = 50  # Maximum tweet length\n","\n","\n","tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding='post', truncating='post')\n","\n","X_test_sequences = tokenizer.texts_to_sequences(X_test)\n","X_test_padded = pad_sequences(X_test_sequences, maxlen=max_length, padding='post', truncating='post')"]},{"cell_type":"markdown","metadata":{"id":"fLAFGUAS1yOi"},"source":["### **CREATION AND TESTING OF THE MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k_t7TTAD1yOi","executionInfo":{"status":"ok","timestamp":1692817100363,"user_tz":-330,"elapsed":1167955,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}},"outputId":"58c361c4-18bf-4799-edb0-16c7795adcb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","800/800 [==============================] - 76s 93ms/step - loss: 0.5981 - accuracy: 0.3670 - val_loss: 0.4893 - val_accuracy: 0.4990\n","Epoch 2/15\n","800/800 [==============================] - 74s 93ms/step - loss: 0.3348 - accuracy: 0.5971 - val_loss: 0.3737 - val_accuracy: 0.5455\n","Epoch 3/15\n","800/800 [==============================] - 74s 93ms/step - loss: 0.1539 - accuracy: 0.6842 - val_loss: 0.3667 - val_accuracy: 0.5715\n","Epoch 4/15\n","800/800 [==============================] - 73s 92ms/step - loss: 0.0880 - accuracy: 0.7190 - val_loss: 0.3692 - val_accuracy: 0.5710\n","Epoch 5/15\n","800/800 [==============================] - 75s 94ms/step - loss: 0.0673 - accuracy: 0.7287 - val_loss: 0.4040 - val_accuracy: 0.6095\n","Epoch 6/15\n","800/800 [==============================] - 74s 93ms/step - loss: 0.0794 - accuracy: 0.7308 - val_loss: 0.4952 - val_accuracy: 0.6070\n","Epoch 7/15\n","800/800 [==============================] - 72s 91ms/step - loss: 0.1094 - accuracy: 0.6894 - val_loss: 0.3997 - val_accuracy: 0.6140\n","Epoch 8/15\n","800/800 [==============================] - 74s 92ms/step - loss: 0.0649 - accuracy: 0.7309 - val_loss: 0.4138 - val_accuracy: 0.6150\n","Epoch 9/15\n","800/800 [==============================] - 73s 91ms/step - loss: 0.0466 - accuracy: 0.7389 - val_loss: 0.4255 - val_accuracy: 0.6250\n","Epoch 10/15\n","800/800 [==============================] - 74s 93ms/step - loss: 0.0522 - accuracy: 0.7386 - val_loss: 0.4514 - val_accuracy: 0.6340\n","Epoch 11/15\n","800/800 [==============================] - 74s 92ms/step - loss: 0.0448 - accuracy: 0.7466 - val_loss: 0.4287 - val_accuracy: 0.6225\n","Epoch 12/15\n","800/800 [==============================] - 74s 93ms/step - loss: 0.0260 - accuracy: 0.7486 - val_loss: 0.4371 - val_accuracy: 0.6195\n","Epoch 13/15\n","800/800 [==============================] - 75s 94ms/step - loss: 0.0201 - accuracy: 0.7527 - val_loss: 0.4357 - val_accuracy: 0.6180\n","Epoch 14/15\n","800/800 [==============================] - 73s 91ms/step - loss: 0.0261 - accuracy: 0.7511 - val_loss: 0.4381 - val_accuracy: 0.6235\n","Epoch 15/15\n","800/800 [==============================] - 75s 94ms/step - loss: 0.0327 - accuracy: 0.7480 - val_loss: 0.4129 - val_accuracy: 0.6355\n","63/63 [==============================] - 3s 31ms/step - loss: 0.4129 - accuracy: 0.6355\n","Test Loss: 0.41286852955818176, accuracy : 0.6355000138282776\n"]}],"source":["model1 = Sequential([\n","    Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    LSTM(64),\n","    Dense(1, activation='tanh')  # Output activation function can be changed based on your needs\n","])\n","\n","\n","\n","model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","model1.fit(X_train_padded, y_train, epochs=15,batch_size = 10,validation_data=(X_test_padded, y_test))\n","\n","# Evaluate model1\n","loss, mae = model1.evaluate(X_test_padded, y_test)\n","print(f\"Test Loss: {loss}, accuracy : {mae}\")\n","\n"]},{"cell_type":"code","source":["model2 = Sequential([\n","    Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    LSTM(128, return_sequences=True),\n","    LSTM(64),\n","    Dense(1, activation='tanh')  # Output activation function can be changed based on your needs\n","])\n","\n","model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","model2.fit(X_train_padded, y_train, epochs=5,validation_data=(X_test_padded, y_test))\n","\n","# Evaluate model2\n","loss, mae = model2.evaluate(X_test_padded, y_test)\n","print(f\"Test Loss: {loss}, accuracy: {mae}\")"],"metadata":{"id":"UUBp6CUz6ceK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_model = Sequential([\n","    Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n","    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n","    Dense(64, activation='relu'),\n","    Dropout(0.1),\n","    Dense(1, activation='tanh')\n","])\n","\n","test_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","test_model.fit(X_train_padded, y_train, epochs=100,batch_size=40,validation_data=(X_test_padded, y_test))\n","\n","# Evaluate test_model\n","loss, mae = test_model.evaluate(X_test_padded, y_test)\n","print(f\"Test Loss: {loss}, accuracy: {mae}\")"],"metadata":{"id":"A1FHYAi0wenX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692825708860,"user_tz":-330,"elapsed":6994802,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}},"outputId":"5fda5dca-0ee4-4b3a-d47d-18b42db7d76f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","200/200 [==============================] - 119s 345ms/step - loss: 0.6223 - accuracy: 0.3503 - val_loss: 0.6239 - val_accuracy: 0.3375\n","Epoch 2/100\n","200/200 [==============================] - 72s 361ms/step - loss: 0.6101 - accuracy: 0.3801 - val_loss: 0.5376 - val_accuracy: 0.5260\n","Epoch 3/100\n","200/200 [==============================] - 67s 337ms/step - loss: 0.3580 - accuracy: 0.5656 - val_loss: 0.3608 - val_accuracy: 0.5425\n","Epoch 4/100\n","200/200 [==============================] - 68s 337ms/step - loss: 0.1542 - accuracy: 0.6805 - val_loss: 0.3611 - val_accuracy: 0.5980\n","Epoch 5/100\n","200/200 [==============================] - 71s 356ms/step - loss: 0.0934 - accuracy: 0.7149 - val_loss: 0.3660 - val_accuracy: 0.5885\n","Epoch 6/100\n","200/200 [==============================] - 69s 347ms/step - loss: 0.1419 - accuracy: 0.7055 - val_loss: 0.4496 - val_accuracy: 0.5625\n","Epoch 7/100\n","200/200 [==============================] - 67s 336ms/step - loss: 0.1027 - accuracy: 0.6992 - val_loss: 0.3947 - val_accuracy: 0.6090\n","Epoch 8/100\n","200/200 [==============================] - 71s 352ms/step - loss: 0.0785 - accuracy: 0.7218 - val_loss: 0.4348 - val_accuracy: 0.6055\n","Epoch 9/100\n","200/200 [==============================] - 69s 346ms/step - loss: 0.0617 - accuracy: 0.7299 - val_loss: 0.4007 - val_accuracy: 0.6335\n","Epoch 10/100\n","200/200 [==============================] - 73s 363ms/step - loss: 0.0521 - accuracy: 0.7343 - val_loss: 0.3896 - val_accuracy: 0.6245\n","Epoch 11/100\n","200/200 [==============================] - 69s 343ms/step - loss: 0.0406 - accuracy: 0.7406 - val_loss: 0.4213 - val_accuracy: 0.6085\n","Epoch 12/100\n","200/200 [==============================] - 70s 351ms/step - loss: 0.0378 - accuracy: 0.7425 - val_loss: 0.4073 - val_accuracy: 0.6170\n","Epoch 13/100\n","200/200 [==============================] - 72s 359ms/step - loss: 0.0347 - accuracy: 0.7454 - val_loss: 0.3910 - val_accuracy: 0.6235\n","Epoch 14/100\n","200/200 [==============================] - 70s 351ms/step - loss: 0.0307 - accuracy: 0.7456 - val_loss: 0.4152 - val_accuracy: 0.6245\n","Epoch 15/100\n","200/200 [==============================] - 70s 351ms/step - loss: 0.0326 - accuracy: 0.7459 - val_loss: 0.3946 - val_accuracy: 0.6305\n","Epoch 16/100\n","200/200 [==============================] - 69s 346ms/step - loss: 0.0402 - accuracy: 0.7444 - val_loss: 0.4190 - val_accuracy: 0.6220\n","Epoch 17/100\n","200/200 [==============================] - 69s 343ms/step - loss: 0.0530 - accuracy: 0.7364 - val_loss: 0.4011 - val_accuracy: 0.6170\n","Epoch 18/100\n","200/200 [==============================] - 71s 354ms/step - loss: 0.0304 - accuracy: 0.7449 - val_loss: 0.4175 - val_accuracy: 0.6130\n","Epoch 19/100\n","200/200 [==============================] - 70s 348ms/step - loss: 0.0317 - accuracy: 0.7464 - val_loss: 0.3916 - val_accuracy: 0.6245\n","Epoch 20/100\n","200/200 [==============================] - 68s 339ms/step - loss: 0.0324 - accuracy: 0.7460 - val_loss: 0.4078 - val_accuracy: 0.6220\n","Epoch 21/100\n","200/200 [==============================] - 71s 357ms/step - loss: 0.0347 - accuracy: 0.7479 - val_loss: 0.3827 - val_accuracy: 0.6220\n","Epoch 22/100\n","200/200 [==============================] - 70s 350ms/step - loss: 0.0270 - accuracy: 0.7495 - val_loss: 0.3957 - val_accuracy: 0.6295\n","Epoch 23/100\n","200/200 [==============================] - 67s 336ms/step - loss: 0.0214 - accuracy: 0.7523 - val_loss: 0.3863 - val_accuracy: 0.6255\n","Epoch 24/100\n","200/200 [==============================] - 72s 357ms/step - loss: 0.0192 - accuracy: 0.7520 - val_loss: 0.4034 - val_accuracy: 0.6145\n","Epoch 25/100\n","200/200 [==============================] - 69s 348ms/step - loss: 0.0197 - accuracy: 0.7526 - val_loss: 0.4106 - val_accuracy: 0.6275\n","Epoch 26/100\n","200/200 [==============================] - 71s 356ms/step - loss: 0.0226 - accuracy: 0.7511 - val_loss: 0.3930 - val_accuracy: 0.6270\n","Epoch 27/100\n","200/200 [==============================] - 67s 338ms/step - loss: 0.0207 - accuracy: 0.7520 - val_loss: 0.4161 - val_accuracy: 0.6275\n","Epoch 28/100\n","200/200 [==============================] - 69s 345ms/step - loss: 0.0191 - accuracy: 0.7520 - val_loss: 0.4062 - val_accuracy: 0.6250\n","Epoch 29/100\n","200/200 [==============================] - 72s 359ms/step - loss: 0.0192 - accuracy: 0.7526 - val_loss: 0.3959 - val_accuracy: 0.6275\n","Epoch 30/100\n","200/200 [==============================] - 68s 339ms/step - loss: 0.0182 - accuracy: 0.7529 - val_loss: 0.4085 - val_accuracy: 0.6385\n","Epoch 31/100\n","200/200 [==============================] - 68s 339ms/step - loss: 0.0201 - accuracy: 0.7502 - val_loss: 0.4071 - val_accuracy: 0.6300\n","Epoch 32/100\n","200/200 [==============================] - 71s 358ms/step - loss: 0.0221 - accuracy: 0.7509 - val_loss: 0.4257 - val_accuracy: 0.6340\n","Epoch 33/100\n","200/200 [==============================] - 73s 364ms/step - loss: 0.0186 - accuracy: 0.7516 - val_loss: 0.4054 - val_accuracy: 0.6300\n","Epoch 34/100\n","200/200 [==============================] - 83s 416ms/step - loss: 0.0388 - accuracy: 0.7509 - val_loss: 0.4564 - val_accuracy: 0.6140\n","Epoch 35/100\n","200/200 [==============================] - 70s 351ms/step - loss: 0.0348 - accuracy: 0.7462 - val_loss: 0.4169 - val_accuracy: 0.6225\n","Epoch 36/100\n","200/200 [==============================] - 71s 355ms/step - loss: 0.0259 - accuracy: 0.7495 - val_loss: 0.4216 - val_accuracy: 0.6210\n","Epoch 37/100\n","200/200 [==============================] - 72s 359ms/step - loss: 0.0251 - accuracy: 0.7495 - val_loss: 0.4586 - val_accuracy: 0.6025\n","Epoch 38/100\n","200/200 [==============================] - 71s 355ms/step - loss: 0.0394 - accuracy: 0.7484 - val_loss: 0.4242 - val_accuracy: 0.6245\n","Epoch 39/100\n","200/200 [==============================] - 70s 351ms/step - loss: 0.0193 - accuracy: 0.7530 - val_loss: 0.4182 - val_accuracy: 0.6255\n","Epoch 40/100\n","200/200 [==============================] - 70s 349ms/step - loss: 0.0203 - accuracy: 0.7525 - val_loss: 0.4273 - val_accuracy: 0.6065\n","Epoch 41/100\n","200/200 [==============================] - 69s 346ms/step - loss: 0.0238 - accuracy: 0.7498 - val_loss: 0.4136 - val_accuracy: 0.6175\n","Epoch 42/100\n","200/200 [==============================] - 70s 350ms/step - loss: 0.0187 - accuracy: 0.7515 - val_loss: 0.3969 - val_accuracy: 0.6335\n","Epoch 43/100\n","200/200 [==============================] - 69s 345ms/step - loss: 0.0166 - accuracy: 0.7539 - val_loss: 0.4138 - val_accuracy: 0.6225\n","Epoch 44/100\n","200/200 [==============================] - 70s 349ms/step - loss: 0.0166 - accuracy: 0.7533 - val_loss: 0.4079 - val_accuracy: 0.6365\n","Epoch 45/100\n","200/200 [==============================] - 71s 354ms/step - loss: 0.0225 - accuracy: 0.7519 - val_loss: 0.4031 - val_accuracy: 0.6305\n","Epoch 46/100\n","200/200 [==============================] - 68s 338ms/step - loss: 0.0176 - accuracy: 0.7524 - val_loss: 0.4289 - val_accuracy: 0.6370\n","Epoch 47/100\n","200/200 [==============================] - 72s 361ms/step - loss: 0.0233 - accuracy: 0.7505 - val_loss: 0.4832 - val_accuracy: 0.5870\n","Epoch 48/100\n","200/200 [==============================] - 70s 352ms/step - loss: 0.0226 - accuracy: 0.7499 - val_loss: 0.4532 - val_accuracy: 0.6360\n","Epoch 49/100\n","200/200 [==============================] - 67s 336ms/step - loss: 0.0166 - accuracy: 0.7526 - val_loss: 0.4307 - val_accuracy: 0.6255\n","Epoch 50/100\n","200/200 [==============================] - 71s 353ms/step - loss: 0.0153 - accuracy: 0.7530 - val_loss: 0.4502 - val_accuracy: 0.6320\n","Epoch 51/100\n","200/200 [==============================] - 67s 335ms/step - loss: 0.0162 - accuracy: 0.7530 - val_loss: 0.4440 - val_accuracy: 0.6240\n","Epoch 52/100\n","200/200 [==============================] - 70s 352ms/step - loss: 0.0157 - accuracy: 0.7529 - val_loss: 0.4546 - val_accuracy: 0.6265\n","Epoch 53/100\n","200/200 [==============================] - 67s 336ms/step - loss: 0.0148 - accuracy: 0.7536 - val_loss: 0.4431 - val_accuracy: 0.6250\n","Epoch 54/100\n","200/200 [==============================] - 68s 339ms/step - loss: 0.0138 - accuracy: 0.7542 - val_loss: 0.4295 - val_accuracy: 0.6275\n","Epoch 55/100\n","200/200 [==============================] - 72s 360ms/step - loss: 0.0182 - accuracy: 0.7536 - val_loss: 0.4320 - val_accuracy: 0.6345\n","Epoch 56/100\n","200/200 [==============================] - 67s 335ms/step - loss: 0.0137 - accuracy: 0.7545 - val_loss: 0.4303 - val_accuracy: 0.6370\n","Epoch 57/100\n","200/200 [==============================] - 68s 339ms/step - loss: 0.0143 - accuracy: 0.7536 - val_loss: 0.4203 - val_accuracy: 0.6090\n","Epoch 58/100\n","200/200 [==============================] - 70s 351ms/step - loss: 0.0132 - accuracy: 0.7536 - val_loss: 0.4417 - val_accuracy: 0.6405\n","Epoch 59/100\n","200/200 [==============================] - 66s 330ms/step - loss: 0.0146 - accuracy: 0.7531 - val_loss: 0.4324 - val_accuracy: 0.6330\n","Epoch 60/100\n","200/200 [==============================] - 71s 356ms/step - loss: 0.0147 - accuracy: 0.7531 - val_loss: 0.4460 - val_accuracy: 0.6325\n","Epoch 61/100\n","200/200 [==============================] - 67s 336ms/step - loss: 0.0139 - accuracy: 0.7539 - val_loss: 0.4184 - val_accuracy: 0.6265\n","Epoch 62/100\n","200/200 [==============================] - 68s 341ms/step - loss: 0.0143 - accuracy: 0.7539 - val_loss: 0.4629 - val_accuracy: 0.6225\n","Epoch 63/100\n","200/200 [==============================] - 71s 353ms/step - loss: 0.0130 - accuracy: 0.7541 - val_loss: 0.4256 - val_accuracy: 0.6415\n","Epoch 64/100\n","200/200 [==============================] - 67s 336ms/step - loss: 0.0150 - accuracy: 0.7539 - val_loss: 0.4461 - val_accuracy: 0.6340\n","Epoch 65/100\n","200/200 [==============================] - 71s 354ms/step - loss: 0.0140 - accuracy: 0.7542 - val_loss: 0.4612 - val_accuracy: 0.6010\n","Epoch 66/100\n","200/200 [==============================] - 71s 354ms/step - loss: 0.0320 - accuracy: 0.7487 - val_loss: 0.4346 - val_accuracy: 0.6390\n","Epoch 67/100\n","200/200 [==============================] - 67s 335ms/step - loss: 0.0204 - accuracy: 0.7521 - val_loss: 0.4241 - val_accuracy: 0.6055\n","Epoch 68/100\n","200/200 [==============================] - 71s 352ms/step - loss: 0.0150 - accuracy: 0.7536 - val_loss: 0.4127 - val_accuracy: 0.6430\n","Epoch 69/100\n","200/200 [==============================] - 68s 342ms/step - loss: 0.0141 - accuracy: 0.7542 - val_loss: 0.4365 - val_accuracy: 0.6505\n","Epoch 70/100\n","200/200 [==============================] - 72s 360ms/step - loss: 0.0136 - accuracy: 0.7539 - val_loss: 0.4115 - val_accuracy: 0.6290\n","Epoch 71/100\n","200/200 [==============================] - 65s 326ms/step - loss: 0.0127 - accuracy: 0.7546 - val_loss: 0.4155 - val_accuracy: 0.6360\n","Epoch 72/100\n","200/200 [==============================] - 68s 341ms/step - loss: 0.0117 - accuracy: 0.7550 - val_loss: 0.4288 - val_accuracy: 0.6420\n","Epoch 73/100\n","200/200 [==============================] - 71s 356ms/step - loss: 0.0124 - accuracy: 0.7546 - val_loss: 0.4244 - val_accuracy: 0.6445\n","Epoch 74/100\n","200/200 [==============================] - 66s 331ms/step - loss: 0.0118 - accuracy: 0.7551 - val_loss: 0.4176 - val_accuracy: 0.6435\n","Epoch 75/100\n","200/200 [==============================] - 70s 350ms/step - loss: 0.0121 - accuracy: 0.7551 - val_loss: 0.4215 - val_accuracy: 0.6500\n","Epoch 76/100\n","200/200 [==============================] - 69s 345ms/step - loss: 0.0116 - accuracy: 0.7550 - val_loss: 0.4603 - val_accuracy: 0.6315\n","Epoch 77/100\n","200/200 [==============================] - 66s 331ms/step - loss: 0.0117 - accuracy: 0.7549 - val_loss: 0.4291 - val_accuracy: 0.6295\n","Epoch 78/100\n","200/200 [==============================] - 71s 357ms/step - loss: 0.0124 - accuracy: 0.7542 - val_loss: 0.4509 - val_accuracy: 0.6295\n","Epoch 79/100\n","200/200 [==============================] - 69s 343ms/step - loss: 0.0133 - accuracy: 0.7545 - val_loss: 0.4480 - val_accuracy: 0.6270\n","Epoch 80/100\n","200/200 [==============================] - 69s 345ms/step - loss: 0.0153 - accuracy: 0.7546 - val_loss: 0.4521 - val_accuracy: 0.6325\n","Epoch 81/100\n","200/200 [==============================] - 68s 339ms/step - loss: 0.0168 - accuracy: 0.7529 - val_loss: 0.4160 - val_accuracy: 0.6500\n","Epoch 82/100\n","200/200 [==============================] - 70s 350ms/step - loss: 0.0129 - accuracy: 0.7540 - val_loss: 0.4056 - val_accuracy: 0.6465\n","Epoch 83/100\n","200/200 [==============================] - 69s 345ms/step - loss: 0.0149 - accuracy: 0.7540 - val_loss: 0.4310 - val_accuracy: 0.6360\n","Epoch 84/100\n","200/200 [==============================] - 68s 340ms/step - loss: 0.0169 - accuracy: 0.7530 - val_loss: 0.4347 - val_accuracy: 0.6485\n","Epoch 85/100\n","200/200 [==============================] - 71s 353ms/step - loss: 0.0201 - accuracy: 0.7536 - val_loss: 0.4599 - val_accuracy: 0.6190\n","Epoch 86/100\n","200/200 [==============================] - 66s 330ms/step - loss: 0.0173 - accuracy: 0.7539 - val_loss: 0.4442 - val_accuracy: 0.6440\n","Epoch 87/100\n","200/200 [==============================] - 67s 334ms/step - loss: 0.0175 - accuracy: 0.7536 - val_loss: 0.4297 - val_accuracy: 0.6375\n","Epoch 88/100\n","200/200 [==============================] - 71s 353ms/step - loss: 0.0115 - accuracy: 0.7551 - val_loss: 0.4260 - val_accuracy: 0.6350\n","Epoch 89/100\n","200/200 [==============================] - 65s 327ms/step - loss: 0.0118 - accuracy: 0.7546 - val_loss: 0.4403 - val_accuracy: 0.6355\n","Epoch 90/100\n","200/200 [==============================] - 71s 353ms/step - loss: 0.0119 - accuracy: 0.7548 - val_loss: 0.4250 - val_accuracy: 0.6385\n","Epoch 91/100\n","200/200 [==============================] - 67s 333ms/step - loss: 0.0115 - accuracy: 0.7549 - val_loss: 0.4347 - val_accuracy: 0.6340\n","Epoch 92/100\n","200/200 [==============================] - 69s 344ms/step - loss: 0.0112 - accuracy: 0.7554 - val_loss: 0.4555 - val_accuracy: 0.6275\n","Epoch 93/100\n","200/200 [==============================] - 70s 350ms/step - loss: 0.0117 - accuracy: 0.7552 - val_loss: 0.4231 - val_accuracy: 0.6285\n","Epoch 94/100\n","200/200 [==============================] - 67s 334ms/step - loss: 0.0169 - accuracy: 0.7549 - val_loss: 0.4557 - val_accuracy: 0.6185\n","Epoch 95/100\n","200/200 [==============================] - 70s 348ms/step - loss: 0.0123 - accuracy: 0.7548 - val_loss: 0.4586 - val_accuracy: 0.6345\n","Epoch 96/100\n","200/200 [==============================] - 66s 332ms/step - loss: 0.0130 - accuracy: 0.7542 - val_loss: 0.4146 - val_accuracy: 0.6225\n","Epoch 97/100\n","200/200 [==============================] - 71s 357ms/step - loss: 0.0122 - accuracy: 0.7544 - val_loss: 0.4424 - val_accuracy: 0.6420\n","Epoch 98/100\n","200/200 [==============================] - 71s 354ms/step - loss: 0.0114 - accuracy: 0.7550 - val_loss: 0.4345 - val_accuracy: 0.6425\n","Epoch 99/100\n","200/200 [==============================] - 66s 330ms/step - loss: 0.0111 - accuracy: 0.7552 - val_loss: 0.4231 - val_accuracy: 0.6470\n","Epoch 100/100\n","200/200 [==============================] - 71s 352ms/step - loss: 0.0108 - accuracy: 0.7554 - val_loss: 0.4378 - val_accuracy: 0.6445\n","63/63 [==============================] - 3s 35ms/step - loss: 0.4378 - accuracy: 0.6445\n","Test Loss: 0.437845379114151, accuracy: 0.6445000171661377\n"]}]},{"cell_type":"markdown","metadata":{"id":"-JjbMX_s1yOi"},"source":["### **SAVING THE MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3oBQF7ne1yOj","executionInfo":{"status":"ok","timestamp":1692817149909,"user_tz":-330,"elapsed":756,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}},"outputId":"4df03a5d-c372-4e27-8c3c-109e8038289c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model1 saved successfully!\n","tokenizer saved successfully!\n"]}],"source":["\n","model1.save('/content/drive/MyDrive/Colab Notebooks/model1_15epoch.h5')\n","print(\"Model1 saved successfully!\")\n","model2.save('/content/drive/MyDrive/Colab Notebooks/model2_5epoch.h5')\n","print(\"Model2 saved successfully!\")\n","tokenizer_filename = \"/content/drive/MyDrive/Colab Notebooks/tokenizer_15epoch.pkl\"\n","with open(tokenizer_filename, 'wb') as tokenizer_file:\n","    pickle.dump(tokenizer, tokenizer_file)\n","print(\"tokenizer saved successfully!\")"]},{"cell_type":"code","source":["test_model.save('/content/drive/MyDrive/Colab Notebooks/test.h5')\n","print(\"Model1 saved successfully!\")\n","tokenizer_filename = \"/content/drive/MyDrive/Colab Notebooks/tokenizertest.pkl\"\n","with open(tokenizer_filename, 'wb') as tokenizer_file:\n","    pickle.dump(tokenizer, tokenizer_file)\n","print(\"tokenizer saved successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQe3O_3X_3BF","executionInfo":{"status":"ok","timestamp":1692825711235,"user_tz":-330,"elapsed":820,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}},"outputId":"f1087c8f-b48f-48c4-abbd-3887bd299a5f"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Model1 saved successfully!\n","tokenizer saved successfully!\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZN8XVAza1yOj"},"source":["### **MODEL LOADING AND TESTING USER INPUT**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzLIhDRP1yOj","executionInfo":{"status":"ok","timestamp":1692815559010,"user_tz":-330,"elapsed":42888,"user":{"displayName":"Hrithvik Kondalkar","userId":"15258123347279561887"}},"outputId":"4a83acaf-6997-4984-ae12-d01590e6b86b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a tweet: People wanting more govt jobs is also a loss to exchequer coz it's not a business that makes money. This is more about tapping a niche in India and paving way for more advanced stuff.\n","1/1 [==============================] - 0s 422ms/step\n","Sentiment prediction for model 1 : 0.22203273\n","1/1 [==============================] - 1s 796ms/step\n","Sentiment prediction for model 2 : -0.00281773\n","Enter a tweet: For the BJP all transactions are a PR exercise that pulls  the wool over the eyes of the public. Even that is not necessary because the public is blind anyway. Few people are able to recognise the difference between transfer of core technology and exploitation of cheap labour.\n","1/1 [==============================] - 0s 34ms/step\n","Sentiment prediction for model 1 : 0.90512955\n","1/1 [==============================] - 0s 45ms/step\n","Sentiment prediction for model 2 : -0.9342344\n","Enter a tweet: How many semiconductor factories we have in india? How many are willing to build them here without any such scheme. Why did in the past 70 we didn't had any such factories?\n","1/1 [==============================] - 0s 37ms/step\n","Sentiment prediction for model 1 : 0.96421164\n","1/1 [==============================] - 0s 40ms/step\n","Sentiment prediction for model 2 : 0.9249864\n"]}],"source":["loaded_model1 = load_model('/content/drive/MyDrive/Colab Notebooks/waste/model1.h5')\n","loaded_model2 = load_model('/content/drive/MyDrive/Colab Notebooks/waste/model2.h5')\n","\n","def predict_sentiment(tweet,model):\n","    preprocessed_tweet = preprocess_text(tweet)\n","    tweet_sequence = tokenizer.texts_to_sequences([preprocessed_tweet])\n","    padded_sequence = pad_sequences(tweet_sequence, maxlen=max_length, padding='post', truncating='post')\n","    sentiment_prediction = model.predict(padded_sequence)[0][0]\n","    return sentiment_prediction\n","\n","for i in range(0,3):\n","    user_tweet = input(\"Enter a tweet: \")\n","    sentiment_prediction = predict_sentiment(user_tweet,loaded_model1)\n","    print(\"Sentiment prediction for model 1 :\", sentiment_prediction)\n","    sentiment_prediction = predict_sentiment(user_tweet,loaded_model2)\n","    print(\"Sentiment prediction for model 2 :\", sentiment_prediction)\n"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}